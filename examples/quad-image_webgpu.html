<html>
  <body>
    <canvas id="container" width="700px" height="450px"></canvas>

    <script id="shader-wgsl" type="x-shader-wgsl">
      @group(0) @binding(0) var mySampler : sampler;
      @group(0) @binding(1) var myTexture : texture_2d<f32>;

      struct VertexOutput {
          @builtin(position) Position : vec4f,
          @location(0) fragUV : vec2f,
      }

      @vertex
      fn vert_main(
          @builtin(vertex_index) VertexIndex : u32
      ) -> VertexOutput {

          var pos = array<vec2f, 6>(
              vec2( 1.0,  1.0), vec2( 1.0, -1.0), vec2(-1.0, -1.0),
              vec2( 1.0,  1.0), vec2(-1.0, -1.0), vec2(-1.0,  1.0),
          );

          const uv = array(
              vec2(1.0, 0.0), vec2(1.0, 1.0), vec2(0.0, 1.0),
              vec2(1.0, 0.0), vec2(0.0, 1.0), vec2(0.0, 0.0),
          );

          var output : VertexOutput;
          output.Position = vec4(pos[VertexIndex], 0.0, 1.0);
          output.fragUV = uv[VertexIndex];
          return output;
      }

      @fragment
      fn frag_main(@location(0) fragUV : vec2f) -> @location(0) vec4f {
          var col = textureSample(myTexture, mySampler, fragUV);

          // branching to illustrate image processing
          if(fragUV.x > .66){

              // invert
              col = 1.0 - col;

          }else if(fragUV.x > .3){

              // grayscale
              col = vec4(col.y, col.y, col.y, 1.0);
          }
          return col;
      }
    </script>
    <script>
      const init = async () => {
        const adapter = await navigator.gpu.requestAdapter();
        const device = await adapter.requestDevice();

        const canvas = document.getElementById('container');
        const context = canvas.getContext('webgpu');

        const devicePixelRatio = window.devicePixelRatio || 1;
        const presentationSize = [
          canvas.clientWidth * devicePixelRatio,
          canvas.clientHeight * devicePixelRatio,
        ];

        const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
        context.configure({
          device,
          size: presentationSize,
          format: presentationFormat,
          alphaMode: 'opaque',
        });

        const shaderModule = device.createShaderModule({
          code: document.getElementById('shader-wgsl').innerText,
        });

        const pipeline = device.createRenderPipeline({
          layout: 'auto',
          vertex: {
            module: shaderModule,
            entryPoint: 'vert_main',
          },
          fragment: {
            module: shaderModule,
            entryPoint: 'frag_main',
            targets: [
              {
                format: presentationFormat,
              },
            ],
          },
          primitive: {
            topology: 'triangle-list',
          },
        });

        const sampler = device.createSampler({
          magFilter: 'linear',
          minFilter: 'linear',
        });

        const img = document.createElement('img');
        img.src = new URL(
          `../assets/Caravaggio_painting.jpg`,
          document.baseURI
        ).href;
        console.log('Loaded Media:', img.src);
        await img.decode();
        const imageBitmap = await createImageBitmap(img);

        const [srcWidth, srcHeight] = [imageBitmap.width, imageBitmap.height];
        const quadTexture = device.createTexture({
          size: [srcWidth, srcHeight, 1],
          format: 'rgba8unorm',
          usage:
            GPUTextureUsage.TEXTURE_BINDING |
            GPUTextureUsage.COPY_DST |
            GPUTextureUsage.RENDER_ATTACHMENT,
        });

        device.queue.copyExternalImageToTexture(
          { source: imageBitmap },
          { texture: quadTexture },
          [imageBitmap.width, imageBitmap.height]
        );

        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [
            {
              binding: 0,
              resource: sampler,
            },
            {
              binding: 1,
              resource: quadTexture.createView(),
            },
          ],
        });

        function frame() {
          const commandEncoder = device.createCommandEncoder();
          const textureView = context.getCurrentTexture().createView();

          const renderPassDescriptor = {
            colorAttachments: [
              {
                view: textureView,
                clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },
                loadOp: 'clear',
                storeOp: 'store',
              },
            ],
          };

          const passEncoder =
            commandEncoder.beginRenderPass(renderPassDescriptor);
          passEncoder.setBindGroup(0, bindGroup);
          passEncoder.setPipeline(pipeline);
          passEncoder.draw(6, 1, 0, 0);
          passEncoder.end();

          device.queue.submit([commandEncoder.finish()]);
          requestAnimationFrame(frame);
        }

        requestAnimationFrame(frame);
      };
      init();
    </script>
  </body>
</html>
